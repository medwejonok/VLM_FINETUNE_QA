{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Fine-Tune VLM (Moondream2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Маликов Денис     \n",
    "Конвейер обучения VLM     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install einops bitsandbytes transformers==4.41.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import display\n",
    "import requests\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "import math\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я выбрал этот датасет, потому что он содержит фотографии различных графов и вопросы с ответами к каждой фотографии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_data(df) :\n",
    "    '''\n",
    "    Функция обрабатывает датасет и возвращает обучающую и тестовую выборки.\n",
    "    '''\n",
    "\n",
    "    image_conversations = {}\n",
    "    for index, row in df.iterrows():\n",
    "        image = row['image']\n",
    "        conversations = row['conversations']\n",
    "        if image not in image_conversations:\n",
    "            image_conversations[image] = []\n",
    "        image_conversations[image].append(conversations)\n",
    "\n",
    "    all_messages = []\n",
    "    for image_name in image_conversations:\n",
    "\n",
    "        image_path = '/content/drive/MyDrive/vlm/dataset/' + image_name\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "\n",
    "        for msg_gpt in image_conversations[image_name]:\n",
    "            gpt = msg_gpt[1]['value']\n",
    "            msg = msg_gpt[0]['value']\n",
    "\n",
    "            if \"\\n<image>\" in msg:\n",
    "                msg = msg.replace(\"\\n<image>\", '')\n",
    "            else:\n",
    "                msg = msg.replace(\"<image>\\n\", '')\n",
    "\n",
    "            if \"\\n\" in gpt:\n",
    "              \n",
    "              def process_gpt_problem(dialog, img):\n",
    "\n",
    "                qas = [dialog[i].replace('Question: ', '') for i in range(0, len(dialog), 2)]\n",
    "                ans = [dialog[i].replace('Answer: ', '') for i in range(1, len(dialog), 2)]\n",
    "\n",
    "                for i in range(len(qas)):\n",
    "                  sample = {\n",
    "                    \"image\": img,\n",
    "                    \"qa\": [\n",
    "                        {\n",
    "                            \"question\": qas[i],\n",
    "                            \"answer\": ans[i],\n",
    "                        }\n",
    "                    ]\n",
    "                  }\n",
    "                  all_messages.append(sample)\n",
    "\n",
    "              process_gpt_problem([x for x in gpt.split('\\n')[1:] if x != ''], image)\n",
    "              temp_gpt = gpt.split('\\n')[0]\n",
    "\n",
    "            else:\n",
    "              temp_gpt = gpt\n",
    "\n",
    "            sample = {\n",
    "                \"image\": image,\n",
    "                \"qa\": [\n",
    "                    {\n",
    "                        \"question\": msg,\n",
    "                        \"answer\": temp_gpt,\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            all_messages.append(sample)\n",
    "\n",
    "    data_train, data_test = train_test_split(all_messages, test_size=0.1, random_state=1337, shuffle=True)\n",
    "    return (data_train, data_test)\n",
    "\n",
    "box_path = '/content/drive/MyDrive/vlm/dataset/box_chart_100examples_simplified_qa.json'\n",
    "candlestick_path = '/content/drive/MyDrive/vlm/dataset/candlestick_chart_100examples_simplified_qa.json'\n",
    "funnel_path = '/content/drive/MyDrive/vlm/dataset/funnel_chart_100examples_simplified_qa.json'\n",
    "gantt_path = '/content/drive/MyDrive/vlm/dataset/gantt_chart_100examples_simplified_qa.json'\n",
    "heatmap_path = '/content/drive/MyDrive/vlm/dataset/heatmap_chart_100examples_simplified_qa.json'\n",
    "polar_path = '/content/drive/MyDrive/vlm/dataset/polar_chart_100examples_simplified_qa.json'\n",
    "scatter_path = '/content/drive/MyDrive/vlm/dataset/scatter_chart_100examples_simplified_qa.json'\n",
    "\n",
    "all_path = [box_path, candlestick_path, funnel_path, gantt_path, heatmap_path, polar_path, scatter_path]\n",
    "\n",
    "dfs = []\n",
    "for path in all_path:\n",
    "    df = pd.read_json(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "data_train, data_test = processed_data(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель на CUDA с весами в float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "DTYPE = torch.float16 \n",
    "MD_REVISION = \"2024-05-20\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vikhyatk/moondream2\", revision=MD_REVISION)\n",
    "moondream = AutoModelForCausalLM.from_pretrained(\n",
    "    \"vikhyatk/moondream2\", revision=MD_REVISION, trust_remote_code=True,\n",
    "    torch_dtype=DTYPE, device_map={\"\": DEVICE}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Гиперпараметры для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUM_STEPS = 2\n",
    "LR = 1e-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Импорт библиотек и определение констант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from bitsandbytes.optim import Adam8bit\n",
    "import math\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "ANSWER_EOS = \"<|endoftext|>\"\n",
    "\n",
    "IMG_TOKENS = 729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Определение функции collate_fn (Data_Collator)\n",
    "\n",
    "Функция collate_fn используется для преобразования батча данных в формат, подходящий для модели.    \n",
    "Она принимает батч данных, преобразует изображения с помощью moondream.vision_encoder, а затем создает токены и метки для каждого вопроса-ответа в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    torch.cuda.empty_cache()\n",
    "    images = [sample['image'] for sample in batch]\n",
    "    images = [moondream.vision_encoder.preprocess(image) for image in images]\n",
    "\n",
    "    labels_acc = []\n",
    "    tokens_acc = []\n",
    "\n",
    "    for sample in batch:\n",
    "        toks = [tokenizer.bos_token_id]\n",
    "        labs = [-100] * (IMG_TOKENS + 1)\n",
    "\n",
    "        for qa in sample['qa']:\n",
    "            q_t = tokenizer(\n",
    "                f\"\\n\\nQuestion: {qa['question']}\\n\\nAnswer:\",\n",
    "                add_special_tokens=False\n",
    "            ).input_ids\n",
    "            toks.extend(q_t)\n",
    "            labs.extend([-100] * len(q_t))\n",
    "\n",
    "            a_t = tokenizer(\n",
    "                f\" {qa['answer']}{ANSWER_EOS}\",\n",
    "                add_special_tokens=False\n",
    "            ).input_ids\n",
    "            toks.extend(a_t)\n",
    "            labs.extend(a_t)\n",
    "\n",
    "        tokens_acc.append(toks)\n",
    "        labels_acc.append(labs)\n",
    "\n",
    "    max_len = -1\n",
    "    for labels in labels_acc:\n",
    "        max_len = max(max_len, len(labels))\n",
    "\n",
    "    attn_mask_acc = []\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        len_i = len(labels_acc[i])\n",
    "        pad_i = max_len - len_i\n",
    "\n",
    "        labels_acc[i].extend([-100] * pad_i)\n",
    "        tokens_acc[i].extend([tokenizer.eos_token_id] * pad_i)\n",
    "        attn_mask_acc.append([1] * len_i + [0] * pad_i)\n",
    "    torch.cuda.empty_cache()\n",
    "    return (\n",
    "        images,\n",
    "        torch.stack([torch.tensor(t, dtype=torch.long) for t in tokens_acc]),\n",
    "        torch.stack([torch.tensor(l, dtype=torch.long) for l in labels_acc]),\n",
    "        torch.stack([torch.tensor(a, dtype=torch.bool) for a in attn_mask_acc]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Определение функции compute_loss\n",
    "\n",
    "Функция compute_loss вычисляет потерю для батча данных.      \n",
    "Она принимает батч данных, преобразует токены и метки в тензоры, а затем использует модель moondream.text_model для вычисления потери."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(batch):\n",
    "    images, tokens, labels, attn_mask = batch\n",
    "\n",
    "    tokens = tokens.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    attn_mask = attn_mask.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_embs = moondream.vision_encoder(images)\n",
    "\n",
    "    tok_embs = moondream.text_model.get_input_embeddings()(tokens)\n",
    "    inputs_embeds = torch.cat((tok_embs[:, 0:1, :], img_embs, tok_embs[:, 1:, :]), dim=1)\n",
    "\n",
    "    outputs = moondream.text_model(\n",
    "        inputs_embeds=inputs_embeds,\n",
    "        labels=labels,\n",
    "        attention_mask=attn_mask,\n",
    "    )\n",
    "\n",
    "    return outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Определение скорости на шаге обучения\n",
    "\n",
    "Функция lr_schedule определяет расписание изменения скорости в зависимости от шага обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(step, max_steps):\n",
    "    x = step / max_steps\n",
    "    if x < 0.1:\n",
    "        return 0.1 * LR + 0.9 * LR * x / 0.1\n",
    "    else:\n",
    "        return 0.1 * LR + 0.9 * LR * (1 + math.cos(math.pi * (x - 0.1))) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Создание DataLoader\n",
    "\n",
    "Создается DataLoader для тренировочного набора данных с помощью функции collate_fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": DataLoader(\n",
    "        data_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Настройка модели для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moondream.text_model.train()\n",
    "moondream.text_model.transformer.gradient_checkpointing_enable()\n",
    "\n",
    "total_steps = EPOCHS * len(dataloaders[\"train\"]) // GRAD_ACCUM_STEPS\n",
    "optimizer = Adam8bit(\n",
    "    [\n",
    "        {\"params\": moondream.text_model.parameters()},\n",
    "    ],\n",
    "    lr=LR * 0.1,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Обучени модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель тренируется в цикле по эпохам.      \n",
    "В каждой эпохе происходит итерация по батчам данных, вычисление потери, обратное распространение ошибки и обновление параметров модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in tqdm(dataloaders[\"train\"], desc=f\"Epoch {epoch + 1}/{EPOCHS}\"):\n",
    "        i += 1\n",
    "\n",
    "        loss = compute_loss(batch)\n",
    "        loss.backward()\n",
    "\n",
    "        if i % GRAD_ACCUM_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            lr = lr_schedule(i / GRAD_ACCUM_STEPS, total_steps)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "\n",
    "\n",
    "moondream.save_pretrained(\"/content/drive/MyDrive/moondream-ft_all_15_epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В наличии 118 тестовых вопросов и овтетов к ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DTYPE = torch.float32 if DEVICE == \"cpu\" else torch.float16 # CPU doesn't support float16\n",
    "MD_REVISION = \"2024-05-20\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vikhyatk/moondream2\", revision=MD_REVISION)\n",
    "moondream_default = AutoModelForCausalLM.from_pretrained(\n",
    "    \"vikhyatk/moondream2\", revision=MD_REVISION, trust_remote_code=True,\n",
    "    torch_dtype=DTYPE, device_map={\"\": DEVICE}\n",
    ")\n",
    "\n",
    "moondream_finetune = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/content/drive/MyDrive/moondream-ft_new_all_15_epoch\", revision=MD_REVISION, trust_remote_code=True,\n",
    "    torch_dtype=DTYPE, device_map={\"\": DEVICE}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moondream_default.eval()\n",
    "moondream_finetune.eval()\n",
    "\n",
    "right = []\n",
    "pred_default = []\n",
    "pred_finetune = []\n",
    "for i, sample in enumerate(data_test):\n",
    "    md_answer_default = moondream_default.answer_question(\n",
    "        moondream_default.encode_image(sample['image']),\n",
    "        sample['qa'][0]['question'],\n",
    "        tokenizer=tokenizer,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    md_answer_finetune = moondream_finetune.answer_question(\n",
    "        moondream_finetune.encode_image(sample['image']),\n",
    "        sample['qa'][0]['question'],\n",
    "        tokenizer=tokenizer,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=5,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "\n",
    "    right.append(sample['qa'][0]['answer'])\n",
    "    pred_default.append(md_answer_default)\n",
    "    pred_finetune.append(md_answer_finetune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем метрики: Accuracy, F1, BLUE, ROGUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дефолтная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность (Accuracy)\n",
    "accuracy = accuracy_score(right, pred_default)\n",
    "print(f'Точность: {accuracy}')\n",
    "\n",
    "# F1-мера\n",
    "f1 = f1_score(right, pred_default, average='micro')\n",
    "print(f'F1-мера: {f1}')\n",
    "\n",
    "import numpy as np\n",
    "blue_score = []\n",
    "for i in range(len(right)):\n",
    "  y_true_tokens = right[i]\n",
    "  y_pred_tokens =  pred_default[i]\n",
    "  bleu = sentence_bleu(y_true_tokens, y_pred_tokens)\n",
    "  blue_score.append(bleu)\n",
    "\n",
    "print(f'BLEU: {np.mean(blue_score)}')\n",
    "\n",
    "# ROUGE\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(pred_default, right, avg=True)\n",
    "print(f'ROUGE: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.0    \n",
    "F1-мера: 0.0      \n",
    "BLEU: 7.3532446158733e-232      \n",
    "ROUGE: {'rouge-1': {'r': 0.12017594916754581, 'p': 0.03504597827353245, 'f': 0.047154155157596966}, 'rouge-2': {'r': 0.023289315726290515, 'p': 0.009176020940726823, 'f': 0.011400834649175393}, 'rouge-l': {'r': 0.11731116689099882, 'p': 0.03236279973896073, 'f': 0.04460934638441449}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель с finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Точность (Accuracy)\n",
    "accuracy = accuracy_score(right, pred_finetune)\n",
    "print(f'Точность: {accuracy}')\n",
    "\n",
    "# F1-мера\n",
    "f1 = f1_score(right, pred_finetune, average='micro')\n",
    "print(f'F1-мера: {f1}')\n",
    "\n",
    "import numpy as np\n",
    "blue_score = []\n",
    "for i in range(len(right)):\n",
    "  y_true_tokens = right[i]\n",
    "  y_pred_tokens =  pred_finetune[i]\n",
    "  bleu = sentence_bleu(y_true_tokens, y_pred_tokens)\n",
    "  blue_score.append(bleu)\n",
    "\n",
    "print(f'BLEU: {np.mean(blue_score)}')\n",
    "\n",
    "# ROUGE\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(pred_finetune, right, avg=True)\n",
    "print(f'ROUGE: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность: 0.3949579831932773      \n",
    "F1-мера: 0.39495798319327724      \n",
    "BLEU: 1.2346845291816845e-231     \n",
    "ROUGE: {'rouge-1': {'r': 0.44676325075484735, 'p': 0.4451853468660191, 'f': 0.4433325794435508}, 'rouge-2': {'r': 0.05921368547418967, 'p': 0.059803921568627454, 'f': 0.059323729035511356}, 'rouge-l': {'r': 0.4459993088144349, 'p': 0.4437847866419295, 'f': 0.44234394869713456}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
